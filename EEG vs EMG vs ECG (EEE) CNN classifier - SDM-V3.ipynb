{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758a4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load useful libraries\n",
    "import os\n",
    "import wfdb as wf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from biosppy.signals import ecg\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "import glob\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Convolution1D, GlobalMaxPool1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2734f7d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data from 'AllData_to_norm.csv'. This file contains 500 of each of these type of signals: ECG, EMG, and EEG labeled as 1, 2 and 3 respectively.\n",
    "# Each row represents a 10 second sample, resampled to 1000 adquisitions per second. \n",
    "# In terms of this sequential data machine learning algorithm, each sample has 10000 features.\n",
    "\n",
    "data=pd.read_csv('AllData_to_norm.csv', header=None) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2648f50e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check for nan values\n",
    "data_clean=data.dropna(axis=0)\n",
    "# 2 out of 1500 samples were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7af229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "      <th>10001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810.00</td>\n",
       "      <td>811.532876</td>\n",
       "      <td>810.00</td>\n",
       "      <td>808.467124</td>\n",
       "      <td>810.00</td>\n",
       "      <td>814.598628</td>\n",
       "      <td>810.00</td>\n",
       "      <td>786.388365</td>\n",
       "      <td>756.00</td>\n",
       "      <td>732.347912</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.00</td>\n",
       "      <td>-186.285922</td>\n",
       "      <td>-200.00</td>\n",
       "      <td>-202.696359</td>\n",
       "      <td>-195.00</td>\n",
       "      <td>-181.303641</td>\n",
       "      <td>-166.00</td>\n",
       "      <td>-153.481796</td>\n",
       "      <td>-148.141748</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527.00</td>\n",
       "      <td>527.292872</td>\n",
       "      <td>527.00</td>\n",
       "      <td>526.707128</td>\n",
       "      <td>527.00</td>\n",
       "      <td>527.878615</td>\n",
       "      <td>527.00</td>\n",
       "      <td>522.528412</td>\n",
       "      <td>517.00</td>\n",
       "      <td>512.882735</td>\n",
       "      <td>...</td>\n",
       "      <td>122.00</td>\n",
       "      <td>113.124255</td>\n",
       "      <td>102.00</td>\n",
       "      <td>94.583582</td>\n",
       "      <td>93.00</td>\n",
       "      <td>98.416418</td>\n",
       "      <td>112.00</td>\n",
       "      <td>134.917908</td>\n",
       "      <td>168.337306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.00</td>\n",
       "      <td>41.501907</td>\n",
       "      <td>34.00</td>\n",
       "      <td>30.248093</td>\n",
       "      <td>34.00</td>\n",
       "      <td>46.505720</td>\n",
       "      <td>59.00</td>\n",
       "      <td>63.229025</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.453178</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-20.963976</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-21.137008</td>\n",
       "      <td>-24.00</td>\n",
       "      <td>-27.112992</td>\n",
       "      <td>-29.00</td>\n",
       "      <td>-28.185040</td>\n",
       "      <td>-23.192128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.874520</td>\n",
       "      <td>-15.00</td>\n",
       "      <td>-15.125480</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>-0.248560</td>\n",
       "      <td>10.00</td>\n",
       "      <td>16.744718</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.769686</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.687185</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.229272</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.229272</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-3.853641</td>\n",
       "      <td>1.668348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.00</td>\n",
       "      <td>273.370362</td>\n",
       "      <td>273.00</td>\n",
       "      <td>272.629638</td>\n",
       "      <td>273.00</td>\n",
       "      <td>274.111086</td>\n",
       "      <td>273.00</td>\n",
       "      <td>267.176017</td>\n",
       "      <td>259.00</td>\n",
       "      <td>251.309845</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>2.913658</td>\n",
       "      <td>10.00</td>\n",
       "      <td>11.737114</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.262886</td>\n",
       "      <td>10.00</td>\n",
       "      <td>18.685570</td>\n",
       "      <td>37.793823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>6.59</td>\n",
       "      <td>-1.130000</td>\n",
       "      <td>-7.17</td>\n",
       "      <td>-5.640000</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.81</td>\n",
       "      <td>-6.700000</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>-7.550000</td>\n",
       "      <td>-9.75</td>\n",
       "      <td>-9.040000</td>\n",
       "      <td>-5.41</td>\n",
       "      <td>-7.170000</td>\n",
       "      <td>-7.800000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>-7.80</td>\n",
       "      <td>-5.600000</td>\n",
       "      <td>-4.96</td>\n",
       "      <td>-7.210000</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>-5.840000</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>-6.740000</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>-4.290000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.16</td>\n",
       "      <td>-3.010000</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>-4.93</td>\n",
       "      <td>-3.630000</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>-2.940000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>-4.09</td>\n",
       "      <td>-4.070000</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>-5.520000</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>-2.360000</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-1.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-2.470000</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-2.040000</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-1.220000</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-1.760000</td>\n",
       "      <td>-1.180000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-1.220000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.530000</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>3.26</td>\n",
       "      <td>-0.690000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.09</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.770000</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-1.290000</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-1.340000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.880000</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.56</td>\n",
       "      <td>-0.680000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1498 rows × 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0           1       2           3       4           5       6      \\\n",
       "0     810.00  811.532876  810.00  808.467124  810.00  814.598628  810.00   \n",
       "1     527.00  527.292872  527.00  526.707128  527.00  527.878615  527.00   \n",
       "2      49.00   41.501907   34.00   30.248093   34.00   46.505720   59.00   \n",
       "3       0.00   -9.874520  -15.00  -15.125480  -10.00   -0.248560   10.00   \n",
       "4     273.00  273.370362  273.00  272.629638  273.00  274.111086  273.00   \n",
       "...      ...         ...     ...         ...     ...         ...     ...   \n",
       "1495    6.59   -1.130000   -7.17   -5.640000   -1.48    0.510000    5.51   \n",
       "1496   -7.80   -5.600000   -4.96   -7.210000   -5.68   -5.840000   -6.40   \n",
       "1497   -4.09   -4.070000   -2.83   -5.520000   -2.79   -2.360000   -2.55   \n",
       "1498   -0.84    0.820000   -2.29   -0.640000    0.31    2.860000    1.93   \n",
       "1499    0.09    3.900000    0.93    0.560000   -1.09   -1.770000   -1.51   \n",
       "\n",
       "           7       8           9      ...   9992        9993    9994   \\\n",
       "0     786.388365  756.00  732.347912  ... -176.00 -186.285922 -200.00   \n",
       "1     522.528412  517.00  512.882735  ...  122.00  113.124255  102.00   \n",
       "2      63.229025   63.00   63.453178  ...  -20.00  -20.963976  -20.00   \n",
       "3      16.744718   20.00   20.769686  ...    5.00    4.687185    5.00   \n",
       "4     267.176017  259.00  251.309845  ...   -5.00    2.913658   10.00   \n",
       "...          ...     ...         ...  ...     ...         ...     ...   \n",
       "1495    5.800000    0.50    0.440000  ...   -7.81   -6.700000   -5.44   \n",
       "1496   -6.740000   -3.92   -4.290000  ...   -4.16   -3.010000   -2.65   \n",
       "1497   -2.690000   -1.02   -1.890000  ...   -0.17   -2.470000   -3.14   \n",
       "1498   -0.040000    1.59   -1.220000  ...   -0.95   -0.530000    1.37   \n",
       "1499   -1.290000   -1.94   -1.340000  ...    0.09   -0.880000   -0.03   \n",
       "\n",
       "           9995    9996        9997    9998        9999        10000  10001  \n",
       "0    -202.696359 -195.00 -181.303641 -166.00 -153.481796 -148.141748      1  \n",
       "1      94.583582   93.00   98.416418  112.00  134.917908  168.337306      1  \n",
       "2     -21.137008  -24.00  -27.112992  -29.00  -28.185040  -23.192128      1  \n",
       "3       3.229272    0.00   -3.229272   -5.00   -3.853641    1.668348      1  \n",
       "4      11.737114   10.00    8.262886   10.00   18.685570   37.793823      1  \n",
       "...          ...     ...         ...     ...         ...         ...    ...  \n",
       "1495   -7.550000   -9.75   -9.040000   -5.41   -7.170000   -7.800000      3  \n",
       "1496   -2.650000   -4.93   -3.630000   -2.36   -2.600000   -2.940000      3  \n",
       "1497   -2.040000   -0.82   -1.220000    0.14   -1.760000   -1.180000      3  \n",
       "1498    1.050000    0.04    0.350000    3.26   -0.690000    1.300000      3  \n",
       "1499    1.810000    2.56   -0.680000    0.12    1.880000    3.510000      3  \n",
       "\n",
       "[1498 rows x 10002 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set X (training data) and y (target variable)\n",
    "cols = data_clean.shape[1]\n",
    "features = data_clean.iloc[:,0:cols-1]\n",
    "target = data_clean.iloc[:,cols-1:cols]\n",
    "data_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb043d1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normalize each sample from 0 to 1\n",
    "features_norm = normalize(features, norm='l2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8101bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create df with normalized samples\n",
    "features_ready=pd.DataFrame(features_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eaf5120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 10001) (1498, 1)\n"
     ]
    }
   ],
   "source": [
    "# sanity check for features and target shape\n",
    "print(features_ready.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06578497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert X and Y from pandas to np\n",
    "X = np.matrix(features_ready.values)\n",
    "Y = np.matrix(target.values)\n",
    "\n",
    "# sanity check\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55207522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into \"training\" and \"test\" datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .20, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f847bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e78eb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check, labels should start from 0 to n, otherwise the softmax function gets confused\n",
    "np.unique(Y_train, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caefbff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting my labels to 0,1,2 instead of 1,2,3\n",
    "Y_train_fix = Y_train-1\n",
    "Y_test_fix = Y_test-1\n",
    "\n",
    "# Sanity check for Y_train_fix \n",
    "np.unique(Y_train_fix, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defbd0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check for Y_test_fix \n",
    "np.unique(Y_test_fix, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5714b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the classifier\n",
    "def EMGEEGECG_classifier():\n",
    "    # defining input shape of each sample\n",
    "    inp = Input(shape=(10001, 1))\n",
    "    # using a convoluted 1D layer with 32 filters, and kernel size=5, activation function = ReLu, padding with zeroes valid\n",
    "    img_1 = Convolution1D(32, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    # The first layer alone underfitted the data, therefore I've used a second convoluted 1D layer with 64 filters, and kernel size=5, activation function = ReLu, padding with zeroes valid\n",
    "    img_1 = Convolution1D(64, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    # Pool the results of the first two layers so they can be digested by the first dense layer, pooling using \"Max\" value\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    \n",
    "    # Two dense layers to classify samples based on output from convolutional layers. One dense layer alone would underfit.\n",
    "    # Last dense layer used softmax activation to return an array of probability scores. \n",
    "    # Each score is the probability that the current sample belongs to one of 3 possible targets.\n",
    "    dense_1 = Dense(3, activation=activations.softmax, name=\"dense_1\")(img_1)\n",
    "\n",
    "    # defining model inputs and outputs, and learning rate (Adam)\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = tf.keras.optimizers.Adam(0.001)\n",
    "    \n",
    "    # defining model optimization, and loss function = sparse_categorical_entropy given that we have more than two categories.\n",
    "    # metric chosen as 'acc' \n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    \n",
    "    # show model summary\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59c63846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10001, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 9997, 32)          192       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 9993, 64)          10304     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 10,691\n",
      "Trainable params: 10,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 1.0604 - acc: 0.3785 - val_loss: 1.0227 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.41667, saving model to EMGEEGECG_classifier_V3.h5\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 0.9264 - acc: 0.5686 - val_loss: 0.8593 - val_acc: 0.6417\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.41667 to 0.64167, saving model to EMGEEGECG_classifier_V3.h5\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - 7s 196ms/step - loss: 0.7398 - acc: 0.6846 - val_loss: 0.6773 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.64167 to 0.70000, saving model to EMGEEGECG_classifier_V3.h5\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 0.5808 - acc: 0.7635 - val_loss: 0.5467 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70000 to 0.79167, saving model to EMGEEGECG_classifier_V3.h5\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 0.4816 - acc: 0.8033 - val_loss: 0.4808 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.79167 to 0.84167, saving model to EMGEEGECG_classifier_V3.h5\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 0.4311 - acc: 0.8302 - val_loss: 0.4205 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.84167\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - 7s 194ms/step - loss: 0.3888 - acc: 0.8432 - val_loss: 0.3865 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.84167\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 0.3649 - acc: 0.8497 - val_loss: 0.3875 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.84167 to 0.85833, saving model to EMGEEGECG_classifier_V3.h5\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 0.3373 - acc: 0.8646 - val_loss: 0.3469 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.85833\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 0.3241 - acc: 0.8516 - val_loss: 0.3200 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.85833 to 0.87500, saving model to EMGEEGECG_classifier_V3.h5\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 0.2968 - acc: 0.8840 - val_loss: 0.2976 - val_acc: 0.8917\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.87500 to 0.89167, saving model to EMGEEGECG_classifier_V3.h5\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - 7s 196ms/step - loss: 0.2841 - acc: 0.8952 - val_loss: 0.3095 - val_acc: 0.8917\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.89167\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - 7s 198ms/step - loss: 0.2641 - acc: 0.9119 - val_loss: 0.2661 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.89167 to 0.90000, saving model to EMGEEGECG_classifier_V3.h5\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - 7s 197ms/step - loss: 0.2478 - acc: 0.9239 - val_loss: 0.2550 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.90000\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - 7s 195ms/step - loss: 0.2276 - acc: 0.9295 - val_loss: 0.2569 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.90000 to 0.90833, saving model to EMGEEGECG_classifier_V3.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Running our classifier over the data, saving it to a file in parallel so we can use it for classification later(checkpoint).\n",
    "# I've plotted Training Loss per Epoch as a performance measure.\n",
    "# 15 Epochs was chosen by trial and error\n",
    "\n",
    "model = EMGEEGECG_classifier()\n",
    "\n",
    "file_path = \"EMGEEGECG_classifier_V3.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=0)\n",
    "callbacks_list = [checkpoint, redonplat]  \n",
    "\n",
    "model.fit(X_train, Y_train_fix, epochs=15, verbose=1, callbacks=callbacks_list, validation_split=0.1)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + model.history.history['loss'], 'o-')\n",
    "ax.legend(['Training Loss'], loc = 0)\n",
    "ax.set_title('Training Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5782afdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9447186664390964 \n"
     ]
    }
   ],
   "source": [
    "# call our model, and calculate f1 score\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model.predict(X_test)\n",
    "pred_test = np.argmax(pred_test, axis=-1)\n",
    "\n",
    "f1 = f1_score(Y_test_fix, pred_test, average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments: I believe that with the addition of more layers, the result would get better. However, I've decided to wait until\n",
    "# I get a better understanding on the principles of neural networks, in the mean time I think this is enough for a proof of concept."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
