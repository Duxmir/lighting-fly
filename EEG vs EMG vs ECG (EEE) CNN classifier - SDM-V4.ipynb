{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "758a4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load useful libraries\n",
    "import os\n",
    "import wfdb as wf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from biosppy.signals import ecg\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "import glob\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Convolution1D, GlobalMaxPool1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image, ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2734f7d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data from 'AllData_to_norm.csv'. This file contains 500 of each of these type of signals: ECG, EMG, and EEG labeled as 1, 2 and 3 respectively.\n",
    "# Each row represents a 10 second sample, resampled to 1000 adquisitions per second. \n",
    "# In terms of this sequential data machine learning algorithm, each sample has 10000 features.\n",
    "\n",
    "data=pd.read_csv('AllData_to_norm.csv', header=None) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2648f50e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check for nan values\n",
    "data_clean=data.dropna(axis=0)\n",
    "# 2 out of 1500 samples were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7af229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "      <th>10001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810.00</td>\n",
       "      <td>811.532876</td>\n",
       "      <td>810.00</td>\n",
       "      <td>808.467124</td>\n",
       "      <td>810.00</td>\n",
       "      <td>814.598628</td>\n",
       "      <td>810.00</td>\n",
       "      <td>786.388365</td>\n",
       "      <td>756.00</td>\n",
       "      <td>732.347912</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.00</td>\n",
       "      <td>-186.285922</td>\n",
       "      <td>-200.00</td>\n",
       "      <td>-202.696359</td>\n",
       "      <td>-195.00</td>\n",
       "      <td>-181.303641</td>\n",
       "      <td>-166.00</td>\n",
       "      <td>-153.481796</td>\n",
       "      <td>-148.141748</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527.00</td>\n",
       "      <td>527.292872</td>\n",
       "      <td>527.00</td>\n",
       "      <td>526.707128</td>\n",
       "      <td>527.00</td>\n",
       "      <td>527.878615</td>\n",
       "      <td>527.00</td>\n",
       "      <td>522.528412</td>\n",
       "      <td>517.00</td>\n",
       "      <td>512.882735</td>\n",
       "      <td>...</td>\n",
       "      <td>122.00</td>\n",
       "      <td>113.124255</td>\n",
       "      <td>102.00</td>\n",
       "      <td>94.583582</td>\n",
       "      <td>93.00</td>\n",
       "      <td>98.416418</td>\n",
       "      <td>112.00</td>\n",
       "      <td>134.917908</td>\n",
       "      <td>168.337306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.00</td>\n",
       "      <td>41.501907</td>\n",
       "      <td>34.00</td>\n",
       "      <td>30.248093</td>\n",
       "      <td>34.00</td>\n",
       "      <td>46.505720</td>\n",
       "      <td>59.00</td>\n",
       "      <td>63.229025</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.453178</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-20.963976</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>-21.137008</td>\n",
       "      <td>-24.00</td>\n",
       "      <td>-27.112992</td>\n",
       "      <td>-29.00</td>\n",
       "      <td>-28.185040</td>\n",
       "      <td>-23.192128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.874520</td>\n",
       "      <td>-15.00</td>\n",
       "      <td>-15.125480</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>-0.248560</td>\n",
       "      <td>10.00</td>\n",
       "      <td>16.744718</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.769686</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.687185</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.229272</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3.229272</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-3.853641</td>\n",
       "      <td>1.668348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.00</td>\n",
       "      <td>273.370362</td>\n",
       "      <td>273.00</td>\n",
       "      <td>272.629638</td>\n",
       "      <td>273.00</td>\n",
       "      <td>274.111086</td>\n",
       "      <td>273.00</td>\n",
       "      <td>267.176017</td>\n",
       "      <td>259.00</td>\n",
       "      <td>251.309845</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>2.913658</td>\n",
       "      <td>10.00</td>\n",
       "      <td>11.737114</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.262886</td>\n",
       "      <td>10.00</td>\n",
       "      <td>18.685570</td>\n",
       "      <td>37.793823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>6.59</td>\n",
       "      <td>-1.130000</td>\n",
       "      <td>-7.17</td>\n",
       "      <td>-5.640000</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.81</td>\n",
       "      <td>-6.700000</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>-7.550000</td>\n",
       "      <td>-9.75</td>\n",
       "      <td>-9.040000</td>\n",
       "      <td>-5.41</td>\n",
       "      <td>-7.170000</td>\n",
       "      <td>-7.800000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>-7.80</td>\n",
       "      <td>-5.600000</td>\n",
       "      <td>-4.96</td>\n",
       "      <td>-7.210000</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>-5.840000</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>-6.740000</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>-4.290000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.16</td>\n",
       "      <td>-3.010000</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>-4.93</td>\n",
       "      <td>-3.630000</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>-2.940000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>-4.09</td>\n",
       "      <td>-4.070000</td>\n",
       "      <td>-2.83</td>\n",
       "      <td>-5.520000</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>-2.360000</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-1.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-2.470000</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-2.040000</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-1.220000</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-1.760000</td>\n",
       "      <td>-1.180000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-1.220000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.530000</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>3.26</td>\n",
       "      <td>-0.690000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.09</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.770000</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-1.290000</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-1.340000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.880000</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.56</td>\n",
       "      <td>-0.680000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1498 rows Ã— 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0           1       2           3       4           5       6      \\\n",
       "0     810.00  811.532876  810.00  808.467124  810.00  814.598628  810.00   \n",
       "1     527.00  527.292872  527.00  526.707128  527.00  527.878615  527.00   \n",
       "2      49.00   41.501907   34.00   30.248093   34.00   46.505720   59.00   \n",
       "3       0.00   -9.874520  -15.00  -15.125480  -10.00   -0.248560   10.00   \n",
       "4     273.00  273.370362  273.00  272.629638  273.00  274.111086  273.00   \n",
       "...      ...         ...     ...         ...     ...         ...     ...   \n",
       "1495    6.59   -1.130000   -7.17   -5.640000   -1.48    0.510000    5.51   \n",
       "1496   -7.80   -5.600000   -4.96   -7.210000   -5.68   -5.840000   -6.40   \n",
       "1497   -4.09   -4.070000   -2.83   -5.520000   -2.79   -2.360000   -2.55   \n",
       "1498   -0.84    0.820000   -2.29   -0.640000    0.31    2.860000    1.93   \n",
       "1499    0.09    3.900000    0.93    0.560000   -1.09   -1.770000   -1.51   \n",
       "\n",
       "           7       8           9      ...   9992        9993    9994   \\\n",
       "0     786.388365  756.00  732.347912  ... -176.00 -186.285922 -200.00   \n",
       "1     522.528412  517.00  512.882735  ...  122.00  113.124255  102.00   \n",
       "2      63.229025   63.00   63.453178  ...  -20.00  -20.963976  -20.00   \n",
       "3      16.744718   20.00   20.769686  ...    5.00    4.687185    5.00   \n",
       "4     267.176017  259.00  251.309845  ...   -5.00    2.913658   10.00   \n",
       "...          ...     ...         ...  ...     ...         ...     ...   \n",
       "1495    5.800000    0.50    0.440000  ...   -7.81   -6.700000   -5.44   \n",
       "1496   -6.740000   -3.92   -4.290000  ...   -4.16   -3.010000   -2.65   \n",
       "1497   -2.690000   -1.02   -1.890000  ...   -0.17   -2.470000   -3.14   \n",
       "1498   -0.040000    1.59   -1.220000  ...   -0.95   -0.530000    1.37   \n",
       "1499   -1.290000   -1.94   -1.340000  ...    0.09   -0.880000   -0.03   \n",
       "\n",
       "           9995    9996        9997    9998        9999        10000  10001  \n",
       "0    -202.696359 -195.00 -181.303641 -166.00 -153.481796 -148.141748      1  \n",
       "1      94.583582   93.00   98.416418  112.00  134.917908  168.337306      1  \n",
       "2     -21.137008  -24.00  -27.112992  -29.00  -28.185040  -23.192128      1  \n",
       "3       3.229272    0.00   -3.229272   -5.00   -3.853641    1.668348      1  \n",
       "4      11.737114   10.00    8.262886   10.00   18.685570   37.793823      1  \n",
       "...          ...     ...         ...     ...         ...         ...    ...  \n",
       "1495   -7.550000   -9.75   -9.040000   -5.41   -7.170000   -7.800000      3  \n",
       "1496   -2.650000   -4.93   -3.630000   -2.36   -2.600000   -2.940000      3  \n",
       "1497   -2.040000   -0.82   -1.220000    0.14   -1.760000   -1.180000      3  \n",
       "1498    1.050000    0.04    0.350000    3.26   -0.690000    1.300000      3  \n",
       "1499    1.810000    2.56   -0.680000    0.12    1.880000    3.510000      3  \n",
       "\n",
       "[1498 rows x 10002 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set X (training data) and y (target variable)\n",
    "cols = data_clean.shape[1]\n",
    "features = data_clean.iloc[:,0:cols-1]\n",
    "target = data_clean.iloc[:,cols-1:cols]\n",
    "data_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb043d1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normalize each sample from 0 to 1\n",
    "features_norm = normalize(features, norm='l2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8101bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create df with normalized samples\n",
    "features_ready=pd.DataFrame(features_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eaf5120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 10001) (1498, 1)\n"
     ]
    }
   ],
   "source": [
    "# sanity check for features and target shape\n",
    "print(features_ready.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06578497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert X and Y from pandas to np\n",
    "X = np.matrix(features_ready.values)\n",
    "Y = np.matrix(target.values)\n",
    "\n",
    "# sanity check\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55207522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into \"training\" and \"test\" datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .20, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f847bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e78eb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check, labels should start from 0 to n, otherwise the softmax function gets confused\n",
    "np.unique(Y_train, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caefbff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting my labels to 0,1,2 instead of 1,2,3\n",
    "Y_train_fix = Y_train-1\n",
    "Y_test_fix = Y_test-1\n",
    "\n",
    "# Sanity check for Y_train_fix \n",
    "np.unique(Y_train_fix, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defbd0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check for Y_test_fix \n",
    "np.unique(Y_test_fix, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5714b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the classifier\n",
    "def EMGEEGECG_classifier():\n",
    "    # defining input shape of each sample\n",
    "    inp = Input(shape=(10001, 1))\n",
    "    # using a convoluted 1D layer with 32 filters, and kernel size=5, activation function = ReLu, padding with zeroes valid\n",
    "    img_1 = Convolution1D(32, kernel_size=100, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    # The first layer alone underfitted the data, therefore I've used a second convoluted 1D layer with 64 filters, and kernel size=5, activation function = ReLu, padding with zeroes valid\n",
    "    img_1 = Convolution1D(64, kernel_size=100, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    # Pool the results of the first two layers so they can be digested by the first dense layer, pooling using \"Max\" value\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    \n",
    "    # Two dense layers to classify samples based on output from convolutional layers. One dense layer alone would underfit.\n",
    "    # Last dense layer used softmax activation to return an array of probability scores. \n",
    "    # Each score is the probability that the current sample belongs to one of 3 possible targets.\n",
    "    dense_1 = Dense(3, activation=activations.softmax, name=\"dense_1\")(img_1)\n",
    "\n",
    "    # defining model inputs and outputs, and learning rate (Adam)\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = tf.keras.optimizers.Adam(0.001)\n",
    "    \n",
    "    # defining model optimization, and loss function = sparse_categorical_entropy given that we have more than two categories.\n",
    "    # metric chosen as 'acc' \n",
    "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    \n",
    "    # show model summary\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59c63846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10001, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 9902, 32)          3232      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 9803, 64)          204864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 208,291\n",
      "Trainable params: 208,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "9/9 [==============================] - 50s 5s/step - loss: 1.0206 - acc: 0.7737 - val_loss: 0.8748 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.65000, saving model to EMGEEGECG_classifier_V4.h5\n",
      "Epoch 2/15\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.7200 - acc: 0.7922 - val_loss: 0.5251 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.65000 to 0.92500, saving model to EMGEEGECG_classifier_V4.h5\n",
      "Epoch 3/15\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.3793 - acc: 0.9555 - val_loss: 0.2801 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92500 to 0.93333, saving model to EMGEEGECG_classifier_V4.h5\n",
      "Epoch 4/15\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.2040 - acc: 0.9527 - val_loss: 0.2054 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.93333 to 0.94167, saving model to EMGEEGECG_classifier_V4.h5\n",
      "Epoch 5/15\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.1488 - acc: 0.9629 - val_loss: 0.1702 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.94167 to 0.95833, saving model to EMGEEGECG_classifier_V4.h5\n",
      "Epoch 6/15\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.1266 - acc: 0.9666 - val_loss: 0.1598 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95833\n",
      "Epoch 7/15\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.1155 - acc: 0.9712 - val_loss: 0.1470 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95833 to 0.96667, saving model to EMGEEGECG_classifier_V4.h5\n",
      "Epoch 8/15\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1075 - acc: 0.9740 - val_loss: 0.1413 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.96667 to 0.97500, saving model to EMGEEGECG_classifier_V4.h5\n",
      "Epoch 9/15\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.0993 - acc: 0.9777 - val_loss: 0.1338 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97500\n",
      "Epoch 10/15\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0938 - acc: 0.9787 - val_loss: 0.1256 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97500\n",
      "Epoch 11/15\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.0859 - acc: 0.9796 - val_loss: 0.1151 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97500\n",
      "Epoch 12/15\n",
      "9/9 [==============================] - 53s 6s/step - loss: 0.0825 - acc: 0.9787 - val_loss: 0.1104 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.97500\n",
      "Epoch 13/15\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.0804 - acc: 0.9824 - val_loss: 0.1086 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.97500\n",
      "Epoch 14/15\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.0796 - acc: 0.9824 - val_loss: 0.1093 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.97500\n",
      "Epoch 15/15\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.0791 - acc: 0.9824 - val_loss: 0.1095 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.97500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Running our classifier over the data, saving it to a file in parallel so we can use it for classification later(checkpoint).\n",
    "# I've plotted Training Loss per Epoch as a performance measure.\n",
    "# 15 Epochs was chosen by trial and error\n",
    "\n",
    "model = EMGEEGECG_classifier()\n",
    "\n",
    "file_path = \"EMGEEGECG_classifier_V4.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=0)\n",
    "callbacks_list = [checkpoint, redonplat]  \n",
    "\n",
    "model.fit(X_train, Y_train_fix, batch_size=128, epochs=15, verbose=1, callbacks=callbacks_list, validation_split=0.1)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + model.history.history['loss'], 'o-')\n",
    "ax.legend(['Training Loss'], loc = 0)\n",
    "ax.set_title('Training Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5782afdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9807621502209131 \n"
     ]
    }
   ],
   "source": [
    "# call our model, and calculate f1 score\n",
    "model.load_weights(file_path)\n",
    "\n",
    "pred_test = model.predict(X_test)\n",
    "pred_test = np.argmax(pred_test, axis=-1)\n",
    "\n",
    "f1 = f1_score(Y_test_fix, pred_test, average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments: I believe that with the addition of more layers, the result would get better. However, I've decided to wait until\n",
    "# I get a better understanding on the principles of neural networks, in the mean time I think this is enough for a proof of concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a56cf119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10001, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 9902, 32)          3232      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 9803, 64)          204864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 208,291\n",
      "Trainable params: 208,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 1.0150 - acc: 0.6224 - val_loss: 0.8560 - val_acc: 0.6333\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63333, saving model to EMGEEGECG_classifier_V4-1.h5\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 49s 5s/step - loss: 0.6708 - acc: 0.8154 - val_loss: 0.4858 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63333 to 0.88333, saving model to EMGEEGECG_classifier_V4-1.h5\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.3419 - acc: 0.9165 - val_loss: 0.3036 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88333\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.2122 - acc: 0.9193 - val_loss: 0.2490 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88333\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1839 - acc: 0.9323 - val_loss: 0.2218 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.88333 to 0.90000, saving model to EMGEEGECG_classifier_V4-1.h5\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.1573 - acc: 0.9434 - val_loss: 0.1918 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.90000 to 0.94167, saving model to EMGEEGECG_classifier_V4-1.h5\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1327 - acc: 0.9555 - val_loss: 0.1949 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.94167\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.1286 - acc: 0.9647 - val_loss: 0.1593 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.94167\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1108 - acc: 0.9712 - val_loss: 0.1458 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.94167 to 0.95833, saving model to EMGEEGECG_classifier_V4-1.h5\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.1053 - acc: 0.9712 - val_loss: 0.1324 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.95833 to 0.96667, saving model to EMGEEGECG_classifier_V4-1.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244525619d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running the model 5 more times to create a cnn-ensemble predictor. epochs number changed to 10 based on first run.\n",
    "#re-run Number 1\n",
    "model = EMGEEGECG_classifier()\n",
    "\n",
    "file_path = \"EMGEEGECG_classifier_V4-1.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=0)\n",
    "callbacks_list = [checkpoint, redonplat]  \n",
    "\n",
    "model.fit(X_train, Y_train_fix, batch_size=128, epochs=10, verbose=1, callbacks=callbacks_list, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70fc16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 10001, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 9902, 32)          3232      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 9803, 64)          204864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 208,291\n",
      "Trainable params: 208,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 1.0188 - acc: 0.8525 - val_loss: 0.8594 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85833, saving model to EMGEEGECG_classifier_V4-2.h5\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.6672 - acc: 0.9416 - val_loss: 0.4449 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85833 to 0.93333, saving model to EMGEEGECG_classifier_V4-2.h5\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.2935 - acc: 0.9620 - val_loss: 0.2283 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93333 to 0.95833, saving model to EMGEEGECG_classifier_V4-2.h5\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.1555 - acc: 0.9657 - val_loss: 0.1847 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95833\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.1265 - acc: 0.9675 - val_loss: 0.1703 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95833\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.1177 - acc: 0.9731 - val_loss: 0.1497 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95833 to 0.96667, saving model to EMGEEGECG_classifier_V4-2.h5\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1155 - acc: 0.9666 - val_loss: 0.1434 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.96667\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.0997 - acc: 0.9759 - val_loss: 0.1615 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.96667\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.0991 - acc: 0.9787 - val_loss: 0.1353 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.96667 to 0.97500, saving model to EMGEEGECG_classifier_V4-2.h5\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.0896 - acc: 0.9805 - val_loss: 0.1321 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24455121580>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-run Number 2\n",
    "model = EMGEEGECG_classifier()\n",
    "\n",
    "file_path = \"EMGEEGECG_classifier_V4-2.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=0)\n",
    "callbacks_list = [checkpoint, redonplat]  \n",
    "\n",
    "model.fit(X_train, Y_train_fix, batch_size=128, epochs=10, verbose=1, callbacks=callbacks_list, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c823a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 10001, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 9902, 32)          3232      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 9803, 64)          204864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 208,291\n",
      "Trainable params: 208,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 51s 6s/step - loss: 1.0192 - acc: 0.8182 - val_loss: 0.8594 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88333, saving model to EMGEEGECG_classifier_V4-3.h5\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.6690 - acc: 0.9462 - val_loss: 0.4521 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88333 to 0.93333, saving model to EMGEEGECG_classifier_V4-3.h5\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.3087 - acc: 0.9406 - val_loss: 0.2748 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.93333\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.1800 - acc: 0.9536 - val_loss: 0.2147 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.93333 to 0.95833, saving model to EMGEEGECG_classifier_V4-3.h5\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1480 - acc: 0.9610 - val_loss: 0.1850 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95833\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.1314 - acc: 0.9694 - val_loss: 0.1696 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95833\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.1172 - acc: 0.9731 - val_loss: 0.1588 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95833 to 0.96667, saving model to EMGEEGECG_classifier_V4-3.h5\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 50s 5s/step - loss: 0.1095 - acc: 0.9750 - val_loss: 0.1558 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.96667\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1068 - acc: 0.9740 - val_loss: 0.1514 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.96667\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1023 - acc: 0.9768 - val_loss: 0.1518 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.96667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24449cf2700>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-run Number 3\n",
    "model = EMGEEGECG_classifier()\n",
    "\n",
    "file_path = \"EMGEEGECG_classifier_V4-3.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=0)\n",
    "callbacks_list = [checkpoint, redonplat]  \n",
    "\n",
    "model.fit(X_train, Y_train_fix, batch_size=128, epochs=10, verbose=1, callbacks=callbacks_list, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05ccc1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 10001, 1)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 9902, 32)          3232      \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 9803, 64)          204864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 208,291\n",
      "Trainable params: 208,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 1.0292 - acc: 0.6716 - val_loss: 0.8932 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87500, saving model to EMGEEGECG_classifier_V4-4.h5\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 51s 6s/step - loss: 0.7081 - acc: 0.9481 - val_loss: 0.4812 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87500 to 0.94167, saving model to EMGEEGECG_classifier_V4-4.h5\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.3186 - acc: 0.9610 - val_loss: 0.2352 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94167 to 0.95833, saving model to EMGEEGECG_classifier_V4-4.h5\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1627 - acc: 0.9666 - val_loss: 0.1798 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.95833\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1309 - acc: 0.9712 - val_loss: 0.1703 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.95833\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1172 - acc: 0.9731 - val_loss: 0.1654 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.95833\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1154 - acc: 0.9694 - val_loss: 0.1585 - val_acc: 0.9583\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.95833\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1062 - acc: 0.9768 - val_loss: 0.1647 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.95833 to 0.96667, saving model to EMGEEGECG_classifier_V4-4.h5\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 50s 6s/step - loss: 0.1073 - acc: 0.9740 - val_loss: 0.1602 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.96667\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 52s 6s/step - loss: 0.1043 - acc: 0.9759 - val_loss: 0.1557 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.96667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2444954d280>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-run Number 4\n",
    "model = EMGEEGECG_classifier()\n",
    "\n",
    "file_path = \"EMGEEGECG_classifier_V4-4.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=0)\n",
    "callbacks_list = [checkpoint, redonplat]  \n",
    "\n",
    "model.fit(X_train, Y_train_fix, batch_size=128, epochs=10, verbose=1, callbacks=callbacks_list, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ac0d473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ensemble_EMGEEGECG_classifier_V4.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sdunomir\\Miniconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "keras_model = tf.keras.models.load_model('EMGEEGECG_classifier_V4.h5', compile=False)\n",
    "keras_model._name = 'model1'\n",
    "keras_model2 = tf.keras.models.load_model('EMGEEGECG_classifier_V4-1.h5', compile=False)\n",
    "keras_model2._name = 'model2'\n",
    "keras_model3 = tf.keras.models.load_model('EMGEEGECG_classifier_V4-2.h5', compile=False)\n",
    "keras_model3._name = 'model3'\n",
    "keras_model4 = tf.keras.models.load_model('EMGEEGECG_classifier_V4-3.h5', compile=False)\n",
    "keras_model4._name = 'model4'\n",
    "keras_model5 = tf.keras.models.load_model('EMGEEGECG_classifier_V4-4.h5', compile=False)\n",
    "keras_model5._name = 'model5'\n",
    "\n",
    "models = [keras_model, keras_model2, keras_model3, keras_model4, keras_model5]\n",
    "model_input = tf.keras.Input(shape=(10001, 1))\n",
    "model_outputs = [model(model_input) for model in models]\n",
    "ensemble_output = tf.keras.layers.Average()(model_outputs)\n",
    "ensemble_model = tf.keras.Model(inputs=model_input, outputs=ensemble_output)  \n",
    "\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "ensemble_model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "\n",
    "ensemble_model.save('ensemble_EMGEEGECG_classifier_V4.tf')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca594003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.layers.core.Dense object at 0x0000024449528D30> and <keras.layers.pooling.GlobalMaxPooling1D object at 0x00000244525F8D00>).\n",
      "Test f1 score : 0.9901029507154052 \n"
     ]
    }
   ],
   "source": [
    "# call our model, and calculate f1 score\n",
    "\n",
    "model.load_weights('ensemble_EMGEEGECG_classifier_V4.tf')\n",
    "\n",
    "pred_test = model.predict(X_test)\n",
    "pred_test = np.argmax(pred_test, axis=-1)\n",
    "\n",
    "f1 = f1_score(Y_test_fix, pred_test, average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d064624b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
